{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import hyperopt\n",
    "print(hyperopt.__version__)\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET = r'Dataset.xlsx'\n",
    "Target_Year = r'T22'\n",
    "PREDICTION_DATASET=r'PR_Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(PATH_DATASET)\n",
    "Features=['LST','NDBI','NDVI','BD','RD','X','Y','SRTM','slope','MNDWI']\n",
    "X = df[Features]\n",
    "print(X.columns)\n",
    "y = df[[Target_Year]]\n",
    "y = y.to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "print(Xs.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(X):\n",
    "  print(\"loop:\", i)\n",
    "  if i == 2:\n",
    "    print( \"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    break\n",
    "  else:\n",
    "    i+=1\n",
    "Xtrain = Xs[train_index]\n",
    "print(np.shape(Xtrain))\n",
    "ytrain = y[train_index]\n",
    "\n",
    "Xtest = Xs[test_index]\n",
    "print(np.shape(Xtest))\n",
    "ytest = y[test_index]\n",
    "\n",
    "\n",
    "\n",
    "param_hyperopt= {\n",
    "    # learning rate\n",
    "    'eta': hp.loguniform('eta', np.log(0.01), np.log(1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 35, 1)),\n",
    "    'n_estimators' : scope.int(hp.quniform('n_estimators', 50, 250, 10)),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 10.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0)\n",
    "    }\n",
    "\n",
    "print(f'Shape of Train {Xtrain.shape}')\n",
    "print(f'Shape of Test {Xtest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt(param_space, X_train, y_train, num_eval):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    def objective_function(params):\n",
    "        reg = XGBRegressor(**params)\n",
    "        score = cross_val_score(reg, Xtrain, ytrain, cv=5).mean()\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_param = fmin(objective_function, \n",
    "                      param_space, \n",
    "                      algo=tpe.suggest, \n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate= np.random.RandomState(1))\n",
    "    loss = [x['result']['loss'] for x in trials.trials]\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    reg_best = XGBRegressor(\n",
    "                            eta=best_param['eta'],\n",
    "                            max_depth=int(best_param['max_depth']),\n",
    "                            n_estimators=int(best_param['n_estimators']),\n",
    "                            min_child_weight=best_param['min_child_weight'],\n",
    "                            colsample_bytree=best_param['colsample_bytree'],\n",
    "                            subsample=best_param['subsample'],\n",
    "                            gamma=best_param['gamma'],\n",
    "                            reg_lambda=best_param['reg_lambda']\n",
    "                            )\n",
    "    reg_best.fit(Xtrain, ytrain)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"##### Results\")\n",
    "    print(\"Score best parameters: \", min(loss)*-1)\n",
    "    print(\"Best parameters: \", best_param)\n",
    "    print(\"Time elapsed: \", time.time() - start)\n",
    "    print(\"Parameter combinations evaluated: \", num_eval)\n",
    "    \n",
    "    return trials, reg_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hyperopt, reg_best = hyperopt(param_hyperopt, Xtrain, ytrain, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "plt.rcParams['font.size'] = 12 \n",
    "losses = [x['result']['loss'] for x in results_hyperopt.trials]\n",
    "best_so_far = np.maximum.accumulate(-np.array(losses))\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(losses) + 1), best_so_far, marker='o', markersize=4, color='green') # مارکرها را کمی کوچکتر کردم\n",
    "plt.title('Hyperopt Convergence Plot')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best CV Score')\n",
    "plt.grid(True)\n",
    "try:\n",
    "    plt.savefig(r'convergence_plot.png', dpi=400, bbox_inches='tight')\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = df.loc[test_index]\n",
    "# Prediction\n",
    "dftest[\"y_pred\"] = reg_best.predict(Xtest)\n",
    "dftest.to_excel(r'TestDS.xlsx', index=False)\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"RMSE: \", np.round(mean_squared_error(dftest[\"y_pred\"], dftest[\"t21\"], squared=False),10))\n",
    "print (\"MAE: \", np.round(mean_absolute_error(dftest[\"y_pred\"], dftest[\"t21\"]),4))\n",
    "print (\"BIAS: \", np.round(np.mean(dftest[\"y_pred\"]- dftest[\"t21\"]),4))\n",
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(dftest[\"y_pred\"], dftest[\"t21\"])\n",
    "print('Pearsons R2 correlation: %.4f' % corr**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde, pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "x, y = dftest[\"y_pred\"].to_numpy(), dftest[\"t21\"].to_numpy()\n",
    "rmse = mean_squared_error(y, x, squared=False)\n",
    "mae = mean_absolute_error(y, x)\n",
    "bias = np.mean(x - y)\n",
    "corr, _ = pearsonr(x, y)\n",
    "r2 = corr**2\n",
    "stats_text = (\n",
    "    f\"$R^2$    : {r2:6.2f}\\n\"\n",
    "    f\"RMSE (°C): {rmse:6.2f}\\n\"\n",
    "    f\"MAE  (°C): {mae:6.2f}\\n\"\n",
    "    f\"BIAS (°C): {bias:6.2f}\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=300)\n",
    "plt.rc('font', family='serif')\n",
    "sb.regplot(x=x, y=y, ax=ax, line_kws={\"color\": \"red\"}, scatter=False)\n",
    "xy = np.vstack([x, y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "sc = ax.scatter(x, y, c=z, s=8, cmap='jet')\n",
    "ax.set_xlabel(\"Measured T2 (°C)\", fontsize=14)\n",
    "ax.set_ylabel(\"Predicted T2 (°C)\", fontsize=14)\n",
    "ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,\n",
    "        fontsize=12, verticalalignment='top', family='monospace',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"white\", alpha=0.7))\n",
    "cbar = plt.colorbar(sc, ax=ax)\n",
    "cbar.set_label(\"Point Density\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"FeatureImportance.png\",\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_FI(Model):\n",
    "    # Get feature importances\n",
    "    feature_importance = Model.feature_importances_\n",
    "\n",
    "    # Calculate total feature importance\n",
    "    total_importance = sum(feature_importance)\n",
    "\n",
    "    # Normalize feature importance to percentages\n",
    "    feature_importance_percentage = (feature_importance / total_importance) * 100\n",
    "\n",
    "    # Create a DataFrame with feature names and their corresponding importance scores\n",
    "    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance_percentage})\n",
    "\n",
    "    # Sort the DataFrame by importance scores in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "    feature_importance_df.to_csv(r'FeatureImportance.csv', index=False)\n",
    "    print('Feature Importance File is generated!!')\n",
    "C_FI(reg_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r'Train_Model.pkl','wb') as f:\n",
    "    pickle.dump(reg_best,f)\n",
    "    print(\"Model Saved!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Pred=pd.read_csv(r'Pred_DS.csv')\n",
    "X_Pred= df_Pred[Features]\n",
    "Xs_Pred=scaler.fit_transform(X_Pred)\n",
    "print(np.shape(Xs_Pred))\n",
    "df_Pred[Target_Year]=reg_best.predict(Xs_Pred)\n",
    "df_Pred.to_excel(r'PD.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
